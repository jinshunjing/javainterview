# Spark

## 基本原理
- 计算模型：MapReduce的替代者
- RDD(Resilient Distributed Dataset)：弹性分布式数据集  
- 算子：flatMap, mapToPair, reduceByKey


## RDD
- 分片Partition: 默认是CPU的核数，每个分片都会被并行处理
- 
